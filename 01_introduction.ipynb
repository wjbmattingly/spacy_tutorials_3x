{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-allocation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-monaco",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-sender",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-cemetery",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bottom-reducing",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-farmer",
   "metadata": {},
   "source": [
    "Throughout this series of notebooks, we will learn about a powerful natural language processing (NLP) library named spaCy. In a previous version of this series (2020), I was working with spaCy 2.0. This series is based around spaCy 3.0 which brings with it a lot of new bells and whistles, including BERT models. We'll cover that towards the end of this series. This notebook, however, is intended for one purpose, preparing the data for processing.\n",
    "\n",
    "The text data that we will work with is the first Harry Potter book by J.K. Rowling. This is a fun toy example because it will give us the chance the work with some real-world data (yes, scholars study Harry Potter) to test the power of the spaCy library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-shame",
   "metadata": {},
   "source": [
    "## Importing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-canvas",
   "metadata": {},
   "source": [
    "In order to clean the text data, we must first open it. In this book, the data is stored in the subfolder \"data\" with the title \"harry_potter.txt\". We will be loading this data so that we can clean it and store it as \"data/harry_potter_cleaned.txt\". In the kernal below, wew open up the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "scenic-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"./data/harry_potter.txt\"\n",
    "with open (file, \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-vessel",
   "metadata": {},
   "source": [
    "Now that we have loaded the data, let's print it off to see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "attended-platinum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter and the Sorcerer's Stone\n",
      "\n",
      "\n",
      "CHAPTER ONE\n",
      "\n",
      "THE BOY WHO LIVED\n",
      "\n",
      "Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say\n",
      "that they were perfectly normal, thank you very much. They were the last\n",
      "people you'd expect to be involved in anything strange or mysterious,\n",
      "because they just didn't hold with such nonsense.\n",
      "\n",
      "Mr. Dursley was the director of a firm called Grunnings, which made\n",
      "drills. He was a big, beefy man with hardly any neck, although he did\n",
      "have a very large mustache. Mrs. Dursley was thin and blonde and had\n",
      "nearly twice the usual amount of neck, which came in very useful as she\n",
      "spent so much of her time craning over garden fences, spying on the\n",
      "neighbors. The Dursleys had a small son called Dudley and in their\n",
      "opinion there was no finer boy anywhere.\n",
      "\n",
      "The Dursleys had everything they wanted, but they also had a secret, and\n",
      "their greatest fear was that somebody would discover it. They didn't\n",
      "think they could bear it if anyone found out about the Potters. Mrs.\n",
      "Potter was Mrs. Dursley's sister, but they hadn't met for several years;\n",
      "in fact, Mrs. Dursley pretended she didn't have a sister, because her\n",
      "sister and her good-for-nothing husband were as unDursleyish as it was\n",
      "possible to be. The Dursleys shuddered to think what the neighbors would\n",
      "say if the Potters arrived in the street. The Dursleys knew that the\n",
      "Potters had a small son, too, but they had never even seen him. This boy\n",
      "was another good reason for keeping the Potters away; they didn't want\n",
      "Dudley mixing with a child like that.\n",
      "\n",
      "When Mr. and Mrs. Dursley woke up on the dull, gray Tuesday our story\n",
      "starts, there was nothing about the cloudy sky outside to suggest that\n",
      "strange and mysterious things would soon be happening all over the\n",
      "country. Mr. Dursley hummed as he picked out his most boring tie for\n",
      "work, and Mrs. Dursley gossiped away happily as she wrestled a screaming\n",
      "Dudley into his high chair.\n",
      "\n",
      "None of them noticed a large, tawny owl flutter past the window.\n",
      "\n",
      "At half past \n"
     ]
    }
   ],
   "source": [
    "print (text[0:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-elite",
   "metadata": {},
   "source": [
    "To the human observer, this looks quite good. But for a machine, this is not in the proper structure. We need to do a few standard cleaning methods on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-clothing",
   "metadata": {},
   "source": [
    "## Cleaning the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sophisticated-branch",
   "metadata": {},
   "source": [
    "Here, we will begin to clean the data to prepare it properly for processing via spaCy. The first thing we will want to do is to separate the entire text into individual chapters. When trying to manipulate textual data in this way, it is always a good idea to look for patterns in the data that will easily allow you to manipulate it. In our case, the Harry Potter text begins each chapter with a capitalized \"CHAPTER\" followed by the number, spelled out. We can use this to split the entire text into chapters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "common-operator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONE\n",
      "\n",
      "THE BOY WHO LIVED\n",
      "\n",
      "Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say\n",
      "that they were perfectly normal, thank you very much. They were the last\n",
      "people you'd expect to be involved in anything strange or mysterious,\n",
      "because they just didn't hold with such nonsense.\n",
      "\n",
      "Mr. Dursley \n"
     ]
    }
   ],
   "source": [
    "chapters = text.split(\"CHAPTER \")[1:]\n",
    "print (chapters[0][0:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-optimization",
   "metadata": {},
   "source": [
    "Now that we have each chapter separated, we can begin to break down the text further. We can tokenize it on the paragraph level and use those paragraphs as our basic size of the data that we will be passing to spaCy. We can take advantage of the fact that each paragraph is separated by two line breaks. Within each paragraph, line breaks indicate a line break in the text. We remove those and replace them with a simple space. This allows for us to have each paragraph stored as a separate object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "adaptive-serbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for chapter in chapters:\n",
    "    paras = []\n",
    "    paragraphs = chapter.split(\"\\n\\n\")\n",
    "    for paragraph in paragraphs:\n",
    "        if paragraph != \"\":\n",
    "            paragraph = paragraph.replace(\"\\n\", \" \")\n",
    "            paras.append(paragraph)\n",
    "    num = paras[0]\n",
    "    title = paras[1]\n",
    "    paras = paras[2:]\n",
    "    data.append((num, title, paras))\n",
    "\n",
    "with open (\"data/harry_potter_cleaned.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for item in data:\n",
    "        f.write(f\"CHAPTER {item[0]}: {item[1]}\"+\"\\n\")\n",
    "        for para in item[2]:\n",
    "            f.write(para+\"\\n\")\n",
    "        f.write(\"\\n\\n\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-surgeon",
   "metadata": {},
   "source": [
    "Now that we have the data cleaned, we can begin analyzing it. Throughout the next few notebooks, this will be our ultimate goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-decrease",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-edgar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-lancaster",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-thinking",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-louisiana",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-trainer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-packet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-steering",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
